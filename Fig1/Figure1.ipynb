{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read fetching, organization, and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis uses the original file names for the sequencing runs. e.g. P3_H1_S10_R1_001.fastq.gz etc etc.\n",
    "To reproduce this analysis, first download the sequencing runs from NCBI Sequence Read Archive, and then rename accordingly:\n",
    "\n",
    "### Tagmentation sequencing data\n",
    "| SRA experiment ID | Original file name | Condition|\n",
    "| ---|---|----|\n",
    "| SRX25615770 | P3_H1_S10_R1_001.fastq.gz | Tagmentation sequencing of DRT2-expressing E. coli: uninfected cells\n",
    "| SRX25615783 | P3_H2_S11_R1_001.fastq.gz | Tagmentation sequencing of DRT2-expressing E. coli: T5-infected cells\n",
    "| SRX25615786 | P3_H3_S12_R1_001.fastq.gz | Tagmentation sequencing of DRT2-expressing E. coli: uninfected cells, YCAA mutant\n",
    "| SRX25615772 | P3_H4_S13_R1_001.fastq.gz | Tagmentation sequencing of DRT2-expressing E. coli: T5-infected cells, YCAA mutant\n",
    "\n",
    "Place renamed reads in folder tagmentation_sequencing/\n",
    "\n",
    "### Strand-specific DNA sequencing data\n",
    "| SRA experiment ID | Original file name (read 1) | Condition|\n",
    "| ---|---|----|\n",
    "| SRX25615771 | P9_D1_S50_R1_001.fastq.gz | ssDNA sequencing of DRT2-expressing E. coli: uninfected cells\n",
    "| SRX25615782 | P9_D2_S51_R1_001.fastq.gz | ssDNA sequencing of DRT2-expressing E. coli: uninfected cells, S1-nuclease treated\n",
    "| SRX25615784 | P9_D3_S52_R1_001.fastq.gz | ssDNA sequencing of DRT2-expressing E. coli: T5-infected cells\n",
    "| SRX25615785 | P9_D4_S53_R1_001.fastq.gz | ssDNA sequencing of DRT2-expressing E. coli: T5-infected cells, S1-nuclease treated\n",
    "| SRX25615787 | P9_D5_S54_R1_001.fastq.gz | ssDNA sequencing of DRT2-expressing E. coli: uninfected cells, YCAA mutant\n",
    "| SRX25615788 | P9_D6_S55_R1_001.fastq.gz | ssDNA sequencing of DRT2-expressing E. coli: uninfected cells, YCAA mutant, S1-nuclease treated\n",
    "| SRX25615773 | P9_D7_S56_R1_001.fastq.gz | ssDNA sequencing of DRT2-expressing E. coli: T5-infected cells, YCAA mutant\n",
    "| SRX25615774 | P9_D8_S57_R1_001.fastq.gz | ssDNA sequencing of DRT2-expressing E. coli: T5-infected cells, YCAA mutant, S1-nuclease treated\n",
    "\n",
    "Place renamed reads in folder ssDNA_sequencing/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read trimming\n",
    "! mkdir tagmentation_sequencing/Trimmed\n",
    "! for input in tagmentation_sequencing/P3*.fastq.gz; do out=tagmentation_sequencing/Trimmed/$(echo $input | sed 's/fastq\\.gz/fastq/'); cutadapt --trim-n -q 20 -m 20 -a CTGTCTCTTATACACATCT -o $out $input; done\n",
    "\n",
    "! mkdir ssDNA_sequencing/Trimmed\n",
    "! for input in ssDNA_sequencing/P9*_R2_001.fastq.gz; do out=ssDNA_sequencing/Trimmed/$(echo $input | sed 's/fastq\\.gz/fastq/'); cutadapt --trim-n -q 20 -m 20 -g ^TTTTTTTTTT -a ACTGTCTCTTATACACATCT -o $out $input; done\n",
    "\n",
    "# read mapping\n",
    "! cd tagmentation_sequencing/sam/\n",
    "! bwa index references_masked.fasta\n",
    "! for i in {1..4}; do bwa mem references_masked.fasta ../Trimmed/P3_H\"$i\"*.fastq > P3_H\"$i\"_masked.sam; done\n",
    "\n",
    "! cd ssDNA_sequencing/sam/\n",
    "! bwa index references_w_spike.fasta\n",
    "! for i in {1..8}; do bwa mem references_w_spike.fasta ../Trimmed/P9_D\"$i\"*.fastq > D\"$i\"_masked.sam; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import helpful packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = 'Helvetica'\n",
    "matplotlib.rcParams['font.size'] = 10\n",
    "matplotlib.rcParams['axes.linewidth'] = 0.5\n",
    "matplotlib.rcParams['xtick.major.width'] = 0.5\n",
    "matplotlib.rcParams['ytick.major.width'] = 0.5\n",
    "\n",
    "matplotlib.rcParams['patch.force_edgecolor'] = True\n",
    "matplotlib.rcParams['patch.linewidth'] = 0.5\n",
    "\n",
    "\n",
    "#Packages for sequence parsing\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from collections import Counter\n",
    "import pysam\n",
    "\n",
    "\n",
    "#Some useful colors and custom colormaps\n",
    "\n",
    "darkgrey = \"#737880\"\n",
    "midgrey = \"#949598\"\n",
    "lightgrey = \"#C8CECE\"\n",
    "lightestgrey = \"#DBDAD5\"\n",
    "greypalette = [darkgrey, midgrey, lightgrey, lightestgrey]\n",
    "drtpalette = [\"#B0492E\", \"#EB6E4A\", \"#E39625\", \"#F5D9AF\"]\n",
    "\n",
    "def hex_to_rgb(h):\n",
    "    h = h.lstrip('#')\n",
    "    return tuple(int(h[i:i+2], 16)/255 for i in (0, 2, 4))\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "mycmap = LinearSegmentedColormap.from_list('drt_cmap', [hex_to_rgb(h) for h in [drtpalette[3], drtpalette[2], drtpalette[1]]], N=100)\n",
    "mycmap.set_bad(color=greypalette[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make hash dictionary for the ncRNA (1-282)\n",
    "\n",
    "ncRNAsequence = Seq(\"GCCCTAAACAAAGGTTTAGGGGTATTGTACAGGTTGTCAAGCCTCCCACAGGTCTTGGTGAAACCAATCACTGTGACGACGGTAAGCAACACTTGGATGATATTCATAATTGACTCCACGCTACTGATTACATTATACAGCATATCTAACATTTGCGGCGAGGTTCACAATTTGTATTTAGGTACTGATTGTGGATGAGAAGGTTGGAGAAAGACCACTTGGTTAAGCCGGAGGATGTGTCCTAGAATTGTCGCTATTCTGTCATCCTCCGGTTTTGCTAAT\")\n",
    "ncRNAsequence_RC = ncRNAsequence.reverse_complement()\n",
    "rollingcirclejunction = Seq(\"ATATCTAACAGGTTGTCAAG\")\n",
    "rollingcirclejunction_RC = rollingcirclejunction.reverse_complement()\n",
    "\n",
    "ncRNAsubstrings = []\n",
    "for i in range(len(ncRNAsequence)-10):\n",
    "    ncRNAsubstrings.append(ncRNAsequence[i:i+11])\n",
    "for i in range(len(ncRNAsequence_RC)-10):\n",
    "    ncRNAsubstrings.append(ncRNAsequence_RC[i:i+11])\n",
    "for i in range(len(rollingcirclejunction)-10):\n",
    "    ncRNAsubstrings.append(rollingcirclejunction[i:i+11])\n",
    "for i in range(len(rollingcirclejunction_RC)-10):\n",
    "    ncRNAsubstrings.append(rollingcirclejunction_RC[i:i+11])\n",
    "\n",
    "# 11 basepairs is the minimum for a unique hash within ncRNA, still some redundancy with the RCA junction\n",
    "substring_counter = Counter(ncRNAsubstrings)\n",
    "print(\"Number of substrings: \", len(ncRNAsubstrings))\n",
    "print(\"Number of unique substrings: \", len(substring_counter.keys()))\n",
    "\n",
    "substrings_dict = {val:idx for idx, val in enumerate(substring_counter.keys())}\n",
    "substrings_dict_for_lookup = {idx:val for idx, val in enumerate(substring_counter.keys())}\n",
    "substrings_set = set(substrings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful functions\n",
    "\n",
    "def make_segments(x, y):\n",
    "    points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "\n",
    "# Interface to LineCollection:\n",
    "\n",
    "def colorline(x, y, z=None, cmap=plt.get_cmap('copper'), norm=plt.Normalize(0.0, 1.0), linewidth=3, alpha=1.0, ax=None):\n",
    "   \n",
    "    # Default colors equally spaced on [0,1]:\n",
    "    if z is None:\n",
    "        z = np.linspace(0.0, 1.0, len(x))\n",
    "           \n",
    "    # Special case if a single number:\n",
    "    if not hasattr(z, \"__iter__\"):  # to check for numerical input -- this is a hack\n",
    "        z = np.array([z])\n",
    "        \n",
    "    z = np.asarray(z)\n",
    "    \n",
    "    segments = make_segments(x, y)\n",
    "    lc = LineCollection(segments, array=z, cmap=cmap, norm=norm, linewidth=linewidth, alpha=alpha)\n",
    "    \n",
    "    #ax = plt.gca()\n",
    "    if ax == None:\n",
    "        ax = plt.gca()\n",
    "    ax.add_collection(lc)\n",
    "    \n",
    "    return lc\n",
    "        \n",
    "\n",
    "def find_longest_consecutive_run_index(lst):\n",
    "    lst = list(lst)\n",
    "    current_start = lst[0]\n",
    "    current_length = 1\n",
    "    longest_start = lst[0]\n",
    "    longest_length = 1\n",
    "\n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] == lst[i - 1] + 1:\n",
    "            current_length += 1\n",
    "        else:\n",
    "            current_start = lst[i]\n",
    "            current_length = 1\n",
    "\n",
    "        if current_length > longest_length:\n",
    "            longest_start = current_start\n",
    "            longest_length = current_length\n",
    "\n",
    "    index = lst.index(longest_start)\n",
    "\n",
    "    return index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_reads(fasta_path, hash_dict):\n",
    "    if isinstance(fasta_path, str):\n",
    "        read_seqs = []\n",
    "        readiter_f = SeqIO.parse(fasta_path, \"fasta\")\n",
    "    \n",
    "        for record_f in readiter_f:\n",
    "            if record_f.id == 'pLG128ncRNA':\n",
    "                continue                           \n",
    "            read_sequence_f = str.upper(str(record_f.seq))\n",
    "            read_sequence_f = read_sequence_f.replace(\"-\",\"\")\n",
    "            read_seqs.append(read_sequence_f)\n",
    "    \n",
    "    else:\n",
    "        read_seqs = fasta_path\n",
    "\n",
    "    hashed_reads = []\n",
    "    substrings_set = set(hash_dict)\n",
    "\n",
    "    for read_sequence_f in read_seqs:\n",
    "        descriptor = []\n",
    "        for i in range(len(read_sequence_f)-10): # used to have -11, this is a mistake!\n",
    "            current_seq = read_sequence_f[i:i+11]\n",
    "            if current_seq in substrings_set:\n",
    "                descriptor.append(hash_dict[current_seq])\n",
    "            else:\n",
    "                descriptor.append(np.nan)\n",
    "        hashed_reads.append(descriptor)\n",
    "\n",
    "    \n",
    "    return hashed_reads\n",
    "\n",
    "\n",
    "def plot_hashing(hashed_reads, strands=None, ax=None, heightweight = 1, minlength=50, skip=4, lw=1):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    orders = []\n",
    "    colors = []\n",
    "\n",
    "    if strands!=None:\n",
    "        strands_using = []\n",
    "\n",
    "    for i, read in enumerate(hashed_reads):\n",
    "        read = np.array(read)\n",
    "        read[read > 500] -= 523 # renumbering the jumps\n",
    "        subread = read[np.isfinite(read)]\n",
    "        if len(subread) > minlength:\n",
    "            if strands==None:\n",
    "                #  find the longest run:\n",
    "                start = find_longest_consecutive_run_index(read)\n",
    "                x = np.arange(read[start]-start, read[start]-start+len(read))\n",
    "                # offset x to be the middle of the hash\n",
    "                x += 6\n",
    "\n",
    "            else:\n",
    "                if strands[i]: # meaning plus strand\n",
    "                    firstfiniteindex = np.where(np.isfinite(read))[0][0]\n",
    "                    start = read[firstfiniteindex] - firstfiniteindex\n",
    "                    x = np.arange(start, start+len(read))\n",
    "                else: #minus strand\n",
    "                    lastfiniteindex = np.where(np.isfinite(read))[0][-1]\n",
    "                    remainder = len(read) - lastfiniteindex\n",
    "                    end = read[lastfiniteindex] + remainder\n",
    "                    x = np.arange(end-len(read), end)\n",
    "                    #offset x to be end of hash\n",
    "                    x+=11\n",
    "\n",
    "            xs.append(x)\n",
    "            ys.append(np.zeros(len(read)))\n",
    "\n",
    "            lowest = read.min()\n",
    "            highest = read.max()\n",
    "\n",
    "            order = lowest * 1000 + highest # arbitrary ordering\n",
    "            orders.append(order)\n",
    "\n",
    "            color = read / 263\n",
    "            colors.append(color)\n",
    "            if strands != None:\n",
    "                strands_using.append(strands[i])\n",
    "    \n",
    "    if strands == None:\n",
    "        order = np.array(orders).argsort()\n",
    "        for i in range(len(order)):\n",
    "            ys[i] += order[i] * heightweight\n",
    "    else:\n",
    "        highest = 0\n",
    "        lowest = 0\n",
    "        for i, strand in enumerate(strands_using):\n",
    "            if strand: # True means plus strand\n",
    "                ys[i] += highest + heightweight\n",
    "                highest += heightweight\n",
    "            else:\n",
    "                ys[i] += lowest - heightweight\n",
    "                lowest -= heightweight\n",
    "    \n",
    "    \n",
    "    if ax == None:\n",
    "        fig, ax = plt.subplots()\n",
    "        \n",
    "    for i in range(0,len(xs),skip):\n",
    "        x = xs[i]\n",
    "        y = ys[i]\n",
    "        color = colors[i]\n",
    "        colorline(x, y, color, cmap=mycmap, linewidth=lw, ax=ax)\n",
    "    \n",
    "    if strands:\n",
    "        ax.set_ylim(lowest,highest)\n",
    "        ax.axhline(0,color='k')\n",
    "        ax.set_xlim(-300,400)\n",
    "    else:\n",
    "        ax.set_ylim(0,i*heightweight*1.1) # 1.1 is padding\n",
    "        ax.set_xlim(-100,320)\n",
    "\n",
    "    return xs, ys, colors, ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tohash_Tn5spike = {}\n",
    "coli = np.zeros(4)\n",
    "t5 = np.zeros(4)\n",
    "plas = np.zeros(4)\n",
    "cc = np.zeros(4)\n",
    "unmapped = np.zeros(4)\n",
    "spike = np.zeros(4)\n",
    "coverage_Tn5spike = {}\n",
    "\n",
    "for i in range(4):\n",
    "    reads_to_hash = []\n",
    "    pysam.sort(\"-o\", \"tmp.bam\", f'tagmentation_sequencing/sam/P3_H{i+1}_masked.sam')\n",
    "    pysam.index(\"tmp.bam\")\n",
    "    samfile = pysam.AlignmentFile('tmp.bam', 'rb')\n",
    "\n",
    "    refs = samfile.references\n",
    "    unmapped[i] = samfile.unmapped\n",
    "    for j in range(4):\n",
    "        ref = refs[j]\n",
    "        [t5,plas,spike,coli][j][i] = samfile.count(contig = ref)\n",
    "    cc[i] = samfile.count(contig = refs[1], start=256, end=376) #20bp in middle of template\n",
    "\n",
    "\n",
    "    for read in samfile.fetch('pLG128'): # fetch reads mapping ncRNA\n",
    "        readseq = read.query_sequence\n",
    "        reads_to_hash.append(readseq)\n",
    "    spike_reads = samfile.count('pMW342_masked')\n",
    "    volume = [4.1,3.4,3.4,6.8][i] # these are the volumes (in uL) of DNA input into the sequencing library. The DNA samples were all extracted from 100 mL culture.\n",
    "    normalization = spike_reads * volume / 1000\n",
    "\n",
    "    coverage = np.zeros(samfile.get_reference_length('pLG128'))\n",
    "    for col in samfile.pileup('pLG128',max_depth=1000000):\n",
    "        coverage[col.reference_pos] = col.nsegments\n",
    "\n",
    "    tohash_Tn5spike[i] = (reads_to_hash, normalization)\n",
    "    coverage_Tn5spike[i] = (coverage, coverage/normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_ratio = (7,3)\n",
    "\n",
    "fix, axs=plt.subplots(figsize=(6,4),ncols=4,nrows=2,sharey='row', sharex=True, height_ratios=height_ratio)\n",
    "for i in [0,2,3,1]: # do 1 last to set the max-y automatically\n",
    "    hashed = hash_reads(tohash_Tn5spike[i][0], substrings_dict)\n",
    "    ax = axs[0, i]\n",
    "    plot_hashing(hashed, heightweight = 150/tohash_Tn5spike[i][1], ax=ax, skip=20, lw=0.4)\n",
    "    ax.set_xlim(-200,400)\n",
    "    ax.set_xticks((0,200))\n",
    "\n",
    "\n",
    "    ax = axs[1,i]\n",
    "    coverage = 150 * coverage_Tn5spike[i][1] # 1 means the normalized version, 0 means raw\n",
    "    coverage_x = np.arange(coverage.size)-227\n",
    "    ax.plot(coverage_x, coverage, color='k',lw=0.5)\n",
    "    ax.fill_between(coverage_x, coverage, color=drtpalette[2])\n",
    "\n",
    "    ax.set_xticks((0,200))\n",
    "plt.savefig(\"Fig1B.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig S2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(8,3), ncols=4)\n",
    "bottom = np.zeros(4)\n",
    "\n",
    "conditions = {'coli': coli, 'cc': cc, 'plasmid':plas-cc, 't5':t5, 'spike':spike }\n",
    "colors = {'coli': greypalette[3],'cc': drtpalette[1], 'plasmid':drtpalette[3], 't5':drtpalette[2], 'spike':greypalette[0] }\n",
    "\n",
    "\n",
    "order = ['coli', 'cc', 'plasmid', 't5', 'spike']\n",
    "\n",
    "for i in range(len(order)):\n",
    "    condition = order[i]\n",
    "    plot = conditions[condition]\n",
    "    color = colors[condition]\n",
    "    axs[0].bar(np.arange(4),plot,bottom=bottom,color=color)\n",
    "    bottom+=plot\n",
    "\n",
    "bottom = np.zeros(4)\n",
    "for i in range(len(order)):\n",
    "    condition = order[i]\n",
    "    plot = (conditions[condition] / (coli+cc+(plas-cc)+t5+spike)) * 100\n",
    "    color = colors[condition]\n",
    "    axs[1].bar(np.arange(4),plot,bottom=bottom,color=color,width=1)\n",
    "    bottom+=plot\n",
    "\n",
    "bottom = np.zeros(4)\n",
    "volume = np.array([4.1,3.4,3.4,6.8]) # these are the volumes (in uL) of DNA input into the sequencing library. The DNA samples were all extracted from 100 mL culture.\n",
    "for i in range(len(order)-1): # exclude spike\n",
    "    condition = order[i]\n",
    "    plot = conditions[condition] / spike / volume * 1000\n",
    "    color = colors[condition]\n",
    "    axs[2].bar(np.arange(4),plot,bottom=bottom,color=color)\n",
    "    bottom+=plot\n",
    "\n",
    "bottom = np.zeros(4)\n",
    "for i in range(len(order)-1):\n",
    "    condition = order[i]\n",
    "    plot = (conditions[condition] / (coli+cc+(plas-cc)+t5)) * 100\n",
    "    color = colors[condition]\n",
    "    axs[3].bar(np.arange(4),plot,bottom=bottom,color=color,width=1)\n",
    "    bottom+=plot\n",
    "\n",
    "for i in range(4):\n",
    "    axs[i].set_xticks(np.arange(4), labels=['−','+']*2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"FigS2A.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tohash_R2 = {}\n",
    "coli = np.zeros(8)\n",
    "t5 = np.zeros(8)\n",
    "plas = np.zeros(8)\n",
    "cc = np.zeros(8)\n",
    "unmapped = np.zeros(8)\n",
    "spike = np.zeros(8)\n",
    "\n",
    "for i in range(8):\n",
    "    reads_to_hash = []\n",
    "    reads_to_hash_strands = []\n",
    "    pysam.sort(\"-o\", \"tmp.bam\", f'ssDNA_sequencing/sam/D{i+1}.sam')\n",
    "    pysam.index(\"tmp.bam\")\n",
    "    samfile = pysam.AlignmentFile('tmp.bam', 'rb')\n",
    "\n",
    "    refs = samfile.references\n",
    "    unmapped[i] = samfile.unmapped\n",
    "    for j in range(4):\n",
    "        ref = refs[j]\n",
    "        [t5,plas,coli,spike][j][i] = samfile.count(contig = ref)\n",
    "    cc[i] = samfile.count(contig = refs[1], start=256, end=376) #20bp in middle of template\n",
    "\n",
    "\n",
    "    for read in samfile.fetch('pLG128'): # fetch reads mapping ncRNA\n",
    "        readseq = read.query_sequence\n",
    "        reads_to_hash.append(readseq)\n",
    "        reads_to_hash_strands.append(read.is_reverse) #flipped from the R1 data\n",
    "    spike_reads = samfile.count('spike')\n",
    "    volume = [4.1,4.1,3.4,3.4,3.4,3.4,6.8,6.8][i] # these are the volumes (in uL) of DNA input into the sequencing library. The DNA samples were all extracted from 100 mL culture.\n",
    "    normalization = spike_reads * volume / 1000\n",
    "\n",
    "    tohash_R2[i] = (reads_to_hash, reads_to_hash_strands, normalization)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_ratio = (8,2)\n",
    "ylim=1500\n",
    "fix, axs=plt.subplots(figsize=(5,4),ncols=4,nrows=2,sharey='row', sharex=True,height_ratios=height_ratio)\n",
    "for i in range(8):\n",
    "    hashed = hash_reads(tohash_R2[i][0], substrings_dict)\n",
    "    ax = axs[i//4, i%4]\n",
    "    plot_hashing(hashed, strands = tohash_R2[i][1], heightweight = 4/tohash_R2[i][2], ax=ax, skip=4)\n",
    "    ax.set_xlim(-200,400)\n",
    "    if i//4:\n",
    "        ax.set_ylim(-ylim * height_ratio[1]/height_ratio[0], ylim * height_ratio[1]/height_ratio[0])\n",
    "    else:\n",
    "        ax.set_ylim(-ylim , ylim)\n",
    "        ax.set_yticks((-ylim+100,0,ylim-100))\n",
    "    ax.set_xticks((0,200))\n",
    "plt.savefig(\"Fig1F.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure S2H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(8,3), ncols=4)\n",
    "bottom = np.zeros(8)\n",
    "\n",
    "conditions = {'coli': coli, 'cc': cc, 'plasmid':plas-cc, 't5':t5, 'spike':spike }\n",
    "colors = {'coli': greypalette[3],'cc': drtpalette[1], 'plasmid':drtpalette[3], 't5':drtpalette[2], 'spike':greypalette[0] }\n",
    "\n",
    "\n",
    "order = ['coli', 'cc', 'plasmid', 't5', 'spike']\n",
    "\n",
    "for i in range(len(order)):\n",
    "    condition = order[i]\n",
    "    plot = conditions[condition]\n",
    "    color = colors[condition]\n",
    "    axs[0].bar(np.arange(8),plot,bottom=bottom,color=color)\n",
    "    bottom+=plot\n",
    "\n",
    "bottom = np.zeros(8)\n",
    "for i in range(len(order)):\n",
    "    condition = order[i]\n",
    "    plot = (conditions[condition] / (coli+cc+(plas-cc)+t5+spike)) * 100\n",
    "    color = colors[condition]\n",
    "    axs[1].bar(np.arange(8),plot,bottom=bottom,color=color,width=1)\n",
    "    bottom+=plot\n",
    "\n",
    "bottom = np.zeros(8)\n",
    "volume = np.array([4.1,4.1,3.4,3.4,3.4,3.4,6.8,6.8]) # these are the volumes (in uL) of DNA input into the sequencing library. The DNA samples were all extracted from 100 mL culture.\n",
    "for i in range(len(order)-1): # exclude spike\n",
    "    condition = order[i]\n",
    "    plot = conditions[condition] / spike / volume * 1000\n",
    "    color = colors[condition]\n",
    "    axs[2].bar(np.arange(8),plot,bottom=bottom,color=color)\n",
    "    bottom+=plot\n",
    "\n",
    "bottom = np.zeros(8)\n",
    "for i in range(len(order)-1):\n",
    "    condition = order[i]\n",
    "    plot = (conditions[condition] / (coli+cc+(plas-cc)+t5)) * 100\n",
    "    color = colors[condition]\n",
    "    axs[3].bar(np.arange(8),plot,bottom=bottom,color=color,width=1)\n",
    "    bottom+=plot\n",
    "\n",
    "for i in range(4):\n",
    "    axs[i].set_xticks(np.arange(8), labels=['−','+']*4)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"FigS2H.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_jump_plus = np.zeros(8)\n",
    "has_jump_minus = np.zeros(8)\n",
    "template_plus = np.zeros(8)\n",
    "template_minus = np.zeros(8)\n",
    "for i in range(8):\n",
    "    strands = tohash_R2[i][1]\n",
    "    hashed = hash_reads(tohash_R2[i][0], substrings_dict)\n",
    "    weight = tohash_R2[i][2] / 10\n",
    "\n",
    "    for j, hash in enumerate(hashed):\n",
    "        jump = any(h in hash for h in [544,545,546,547,548,549,550])\n",
    "        template_mapping = any(h in hash for h in list(range(30,150)))\n",
    "        if strands[j]:\n",
    "            has_jump_plus[i]+=jump / weight \n",
    "            template_plus[i] += template_mapping / weight \n",
    "        else:\n",
    "            has_jump_minus[i]+=jump / weight \n",
    "            template_minus[i] += template_mapping / weight \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, axs=plt.subplots(figsize=(4,4),ncols=2,sharey=False)\n",
    "axs[0].bar(np.arange(8), template_plus, color=drtpalette[3])\n",
    "axs[0].bar(np.arange(8), template_minus * -1, color=drtpalette[2])\n",
    "axs[0].set_ylabel('normalized template-mapping reads')\n",
    "axs[1].bar(np.arange(8), has_jump_plus, color=drtpalette[3])\n",
    "axs[1].bar(np.arange(8), has_jump_minus * -1, color=drtpalette[2])\n",
    "axs[1].set_ylabel('normalized repeat junction-mapping reads')\n",
    "axs[0].set_xticks(np.arange(8))\n",
    "axs[1].set_xticks(np.arange(8))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Fig1G.pdf\", transparent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioconda2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
