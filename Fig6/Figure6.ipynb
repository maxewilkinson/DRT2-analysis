{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cc1ee7a",
   "metadata": {},
   "source": [
    "# Nanopore Read Analysis\n",
    "Mostly by David Li, with some tweaks by Max Wilkinson\n",
    "\n",
    "Analysis of DRT2 nanopore sequencing data generated from in vitro cDNA production, RNase clean-up, 3' adaptor ligation with 5app ligase, second strand synthesis, and nanopore ligation sequencing kit\n",
    "\n",
    "Strategy:\n",
    "- Filter reads for specific expected structure\n",
    "    - NanoporeAdaptor - Read - RE1021 for cDNA+ strand\n",
    "    - NanoporeAdaptor - RE1021_RC - Read - NanoporeAdaptor_RC for cDNA- strand\n",
    "- Output reads fitting either filter, and also reads failing to pass filter\n",
    "- Make a lookup and hash on 11 bps start and end to see biggest transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba7ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import helpful packages\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Packages for data analysis and plotting\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator)\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "matplotlib.rcParams['font.sans-serif'] = 'Helvetica'\n",
    "matplotlib.rcParams['font.size'] = 10\n",
    "matplotlib.rcParams['axes.linewidth'] = 0.5\n",
    "matplotlib.rcParams['xtick.major.width'] = 0.5\n",
    "matplotlib.rcParams['ytick.major.width'] = 0.5\n",
    "\n",
    "matplotlib.rcParams['patch.force_edgecolor'] = False\n",
    "matplotlib.rcParams['patch.linewidth'] = 0.5\n",
    "\n",
    "\n",
    "#Packages for sequence parsing\n",
    "import regex as re \n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqFeature\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation, ExactPosition, BeforePosition, AfterPosition\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "#Some colours\n",
    "\n",
    "hanpink = \"#DC3860\"\n",
    "hanpink_dark = \"#C63F59\"\n",
    "hanpink_light = \"#F1617A\"\n",
    "hanpink_lightest = \"#E686AC\"\n",
    "hanpinkpalette = [hanpink_dark, hanpink, hanpink_light, hanpink_lightest]\n",
    "\n",
    "darkgrey = \"#737880\"\n",
    "midgrey = \"#949598\"\n",
    "lightgrey = \"#C8CECE\"\n",
    "lightestgrey = \"#DBDAD5\"\n",
    "greypalette = [darkgrey, midgrey, lightgrey, lightestgrey]\n",
    "\n",
    "pinkgreypalette = []\n",
    "for i in range(4):\n",
    "    if i%2 == 0:\n",
    "        pinkgreypalette.append(hanpinkpalette[-i])\n",
    "    else:\n",
    "        pinkgreypalette.append(greypalette[-i])\n",
    "\n",
    "drtpalette = [\"#B0492E\", \"#EB6E4A\", \"#E39625\", \"#F5D9AF\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72027e07",
   "metadata": {},
   "source": [
    "## Filtering out reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a638f50",
   "metadata": {},
   "source": [
    "We will split reads into a few types and will output both the filtered reads and the trimmed reads\n",
    " - 1: NanoporeAdaptor - read - RE1021 in last 100 bp\n",
    " - 2: NanoporeAdaptor - RE1021_RC in the next 100 bp\n",
    " - 3: Any other read with easily detectable NanoporeAdaptor in first 500 bp\n",
    " - 4: Anything left over\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7e6437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "num_reads = 0\n",
    "group1_reads = 0\n",
    "group2_reads = 0\n",
    "group3_reads = 0\n",
    "group4_reads = 0\n",
    "group1_reads_list = []\n",
    "group1trimmed_reads_list = []\n",
    "group2_reads_list = []\n",
    "group2trimmed_reads_list = []\n",
    "group3_reads_list = []\n",
    "group3trimmed_reads_list = []\n",
    "group4_reads_list = []\n",
    "\n",
    "# Process input strings and define regexes\n",
    "NanoporeAdaptor = \"TGTACTTCGTTCAGTTACGTATTGCT\" # aka SQK-NSK007\n",
    "RE1021 = \"CTGTCTCTTATACACATCTCCGAGCCCACGAGAC\"\n",
    "RE1439 =\"GTCTCGTGGGCTCGGAGATGTGTATAAGAGACAG\" # aka RE1021 RC\n",
    "\n",
    "allowed_errors = 5\n",
    "error_string = \"{\"+f\"e<={allowed_errors}\"+\"}\"   \n",
    "adaptor_pattern = f\"(?e)({NanoporeAdaptor}){error_string}\"\n",
    "RE1021_pattern = f\"(?e)({RE1021}){error_string}\"\n",
    "RE1439_pattern = f\"(?e)({RE1439}){error_string}\"\n",
    "\n",
    "# Extract and iterate through reads from .fastq file\n",
    "# Reads are not in GitHub repository due to size limits, please download from NCBI SRA instead\n",
    "readiter_f = SeqIO.parse(\"all_passed_guppy_reads.fastq\", \"fastq\")\n",
    "for record_f in readiter_f:\n",
    "    num_reads += 1\n",
    "    read_sequence_f = str.upper(str(record_f.seq))\n",
    "    \n",
    "    if len(read_sequence_f) >=500:\n",
    "        read_start = read_sequence_f[:500]\n",
    "    else:\n",
    "        read_start = read_sequence_f\n",
    "    \n",
    "    adaptor_match = re.search(adaptor_pattern, read_start)\n",
    "    if adaptor_match:\n",
    "        trimmed = record_f.upper()\n",
    "        trimmed = trimmed[adaptor_match.end():]\n",
    "        trimmed_start = str.upper(str(trimmed.seq[:100]))\n",
    "        trimmed_end = str.upper(str(trimmed.seq[-100:]))\n",
    "        trimmed_end_match = re.search(RE1021_pattern, trimmed_end)\n",
    "        if trimmed_end_match:\n",
    "            group1_reads += 1\n",
    "            group1_reads_list.append(record_f)\n",
    "            trimmed = trimmed[:-(100-trimmed_end_match.start())]\n",
    "            group1trimmed_reads_list.append(trimmed)\n",
    "        else:\n",
    "            trimmed_start_match = re.search(RE1439_pattern, trimmed_start)\n",
    "            if trimmed_start_match:\n",
    "                group2_reads += 1\n",
    "                group2_reads_list.append(record_f)\n",
    "                trimmed = trimmed[trimmed_start_match.end():]\n",
    "                group2trimmed_reads_list.append(trimmed)\n",
    "            else:\n",
    "                group3_reads += 1\n",
    "                group3_reads_list.append(record_f)\n",
    "                group3trimmed_reads_list.append(trimmed)                            \n",
    "    else:\n",
    "        group4_reads += 1\n",
    "        group4_reads_list.append(record_f)\n",
    "\n",
    "         \n",
    "# Output statistics and write .fastq files\n",
    "print(num_reads,\" total reads, \", group1_reads,\" group 1 reads, \", group2_reads,\" group 2 reads, \", group3_reads,\" group 3 reads, and \", group4_reads,\" group 4 reads\")\n",
    "              \n",
    "\n",
    "# Crashed here!\n",
    "clean_group1trimmed_reads = []\n",
    "for read in group1trimmed_reads_list:\n",
    "    if type(read) == type(group1trimmed_reads_list[0]):\n",
    "        clean_group1trimmed_reads.append(read)\n",
    "\n",
    "SeqIO.write(clean_group1trimmed_reads, \"Group1TrimmedReads.fastq\", \"fastq\")\n",
    "\n",
    "clean_group2trimmed_reads = []\n",
    "for read in group2trimmed_reads_list:\n",
    "    if type(read) == type(group1trimmed_reads_list[0]):\n",
    "        clean_group2trimmed_reads.append(read)\n",
    "\n",
    "SeqIO.write(clean_group2trimmed_reads, \"Group2TrimmedReads.fastq\", \"fastq\")\n",
    "\n",
    "clean_group3trimmed_reads = []\n",
    "for read in group3trimmed_reads_list:\n",
    "    if type(read) == type(group1trimmed_reads_list[0]):\n",
    "        clean_group3trimmed_reads.append(read)\n",
    "\n",
    "SeqIO.write(clean_group3trimmed_reads, \"Group3TrimmedReads.fastq\", \"fastq\")                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e13fdaa",
   "metadata": {},
   "source": [
    "# Hash table counting of reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca15e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary of substrings\n",
    "\n",
    "ncRNAsequence = Seq(\"GCCCTAAACAAAGGTTTAGGGGTATTGTACAGGTTGTCAAGCCTCCCACAGGTCTTGGTGAAACCAATCACTGTGACGACGGTAAGCAACACTTGGATGATATTCATAATTGACTCCACGCTACTGATTACATTATACAGCATATCTAACATTTGCGGCGAGGTTCACAATTTGTATTTAGGTACTGATTGTGGATGAGAAGGTTGGAGAAAGACCACTTGGTTAAGCCGGAGGATGTGTCCTAGAATTGTCGCTATTCTGTCATCCTCCGGTTTTGCTAAT\")\n",
    "ncRNAsequence_RC = ncRNAsequence.reverse_complement()\n",
    "rollingcirclejunction = Seq(\"ATATCTAACAGGTTGTCAAG\")\n",
    "rollingcirclejunction_RC = rollingcirclejunction.reverse_complement()\n",
    "\n",
    "ncRNAsubstrings = []\n",
    "for i in range(len(ncRNAsequence)-10):\n",
    "    ncRNAsubstrings.append(ncRNAsequence[i:i+11])\n",
    "for i in range(len(ncRNAsequence_RC)-10):\n",
    "    ncRNAsubstrings.append(ncRNAsequence_RC[i:i+11])\n",
    "for i in range(len(rollingcirclejunction)-10):\n",
    "    ncRNAsubstrings.append(rollingcirclejunction[i:i+11])\n",
    "for i in range(len(rollingcirclejunction_RC)-10):\n",
    "    ncRNAsubstrings.append(rollingcirclejunction_RC[i:i+11])\n",
    "\n",
    "# 11 basepairs is the minimum for a unique hash within ncRNA, still some redundancy with the RCA junction\n",
    "substring_counter = Counter(ncRNAsubstrings)\n",
    "print(\"Number of substrings: \", len(ncRNAsubstrings))\n",
    "print(\"Number of unique substrings: \", len(substring_counter.keys()))\n",
    "\n",
    "substrings_dict = {val:idx for idx, val in enumerate(substring_counter.keys())}\n",
    "substrings_dict_for_lookup = {idx:val for idx, val in enumerate(substring_counter.keys())}\n",
    "substrings_set = set(substrings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab602a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check where reads start and end\n",
    "\n",
    "# Extract and iterate through reads from .fastq file\n",
    "readiter_f = SeqIO.parse(\"Group1TrimmedReads.fastq\", \"fastq\")\n",
    "num_reads = 0\n",
    "num_reads_start_unmatched = 0\n",
    "unmatched_starts = []\n",
    "num_reads_end_unmatched = 0\n",
    "unmatched_ends = []\n",
    "start_array = np.zeros((len(substrings_dict),2))\n",
    "\n",
    "for record_f in readiter_f:\n",
    "    num_reads += 1                               \n",
    "    read_sequence_f = str.upper(str(record_f.seq))\n",
    "    read_start = read_sequence_f[:11]\n",
    "    read_end = read_sequence_f[-11:]\n",
    "                                      \n",
    "    if read_start in substrings_set:\n",
    "        start_array[substrings_dict[read_start],0]+=1\n",
    "    else:\n",
    "        num_reads_start_unmatched += 1\n",
    "        unmatched_starts.append(read_start)\n",
    "    \n",
    "    if read_end in substrings_set:\n",
    "        start_array[substrings_dict[read_end],1]+=1\n",
    "    else:\n",
    "        num_reads_end_unmatched += 1\n",
    "        unmatched_ends.append(read_end)\n",
    "\n",
    "\n",
    "print(f\"Total reads = {num_reads}, Unmatched starts = {num_reads_start_unmatched}, Unmatched ends = {num_reads_end_unmatched}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3004819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out sequence of most common element\n",
    "\n",
    "substrings_dict_for_lookup[np.argmax(start_array[:, 0])]\n",
    "\n",
    "# Starts most commonly at the DNA primer as seen in the cryoEM structure! - great :)\n",
    "# 'CGATATGCTGT': 3080, 'GCATTATGCTG': 2141, 'GTATGCTGTAT': 1800, 'GAAGTATGCTG': 1727, 'TTATGCTGTAT': 1403, 'CATTATGCTGT': 1222\n",
    "# Most common start reads that don't match are SNPs/indels on this most common start primer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "sense_x = np.arange(0,272)\n",
    "antisense_x = np.arange(272,544)\n",
    "\n",
    "start_frequency = start_array[:,0]/start_array[:,0].sum()\n",
    "\n",
    "ax.plot(1+sense_x, start_frequency[sense_x], color=darkgrey)\n",
    "ax.plot(554- antisense_x, start_frequency[antisense_x], color=hanpink)\n",
    "ax.set_xlim(0,300)\n",
    "ax.set_xlabel('mapping position of read start (bp)')\n",
    "ax.set_ylabel('frequency')\n",
    "plt.savefig(\"Figure6B.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe63471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash map of counting where things go now\n",
    "# Check where reads start and end\n",
    "\n",
    "# Extract and iterate through reads from .fastq file\n",
    "readiter_f = SeqIO.parse(\"Group1TrimmedReads.fastq\", \"fastq\")\n",
    "\n",
    "num_reads = 0\n",
    "num_reads_jumpstart_unmatched = 0\n",
    "unmatched_jumpstarts = []\n",
    "num_reads_jumpend_unmatched = 0\n",
    "unmatched_jumpends = []\n",
    "good_jumpreads = 0\n",
    "reads_with_good_jumps = 0\n",
    "read_jump_array = np.zeros((len(substrings_dict),len(substrings_dict)))\n",
    "\n",
    "for record_f in readiter_f:\n",
    "    num_reads += 1                               \n",
    "    read_sequence_f = str.upper(str(record_f.seq))\n",
    "\n",
    "    has_good_jumps = False\n",
    "    \n",
    "    for i in range(len(read_sequence_f)-21):\n",
    "        current_seq = read_sequence_f[i:i+22]\n",
    "        current_seq_start=current_seq[:11]\n",
    "        current_seq_end=current_seq[11:]\n",
    "        if current_seq_start in substrings_set:\n",
    "            if current_seq_end in substrings_set:\n",
    "                good_jumpreads += 1\n",
    "                has_good_jumps = True\n",
    "                read_jump_array[substrings_dict[current_seq_start],substrings_dict[current_seq_end]]+=1\n",
    "            else:\n",
    "                num_reads_jumpend_unmatched += 1\n",
    "                unmatched_jumpends.append(current_seq_end)\n",
    "        else:\n",
    "            num_reads_jumpstart_unmatched += 1\n",
    "            unmatched_jumpstarts.append(current_seq_start)\n",
    "    if has_good_jumps:\n",
    "        reads_with_good_jumps +=1\n",
    "\n",
    "print(f\"Total reads = {num_reads}, Good jumpreads = {good_jumpreads}, Reads with good jumps = {reads_with_good_jumps}, Unmatched jumpstarts = {num_reads_jumpstart_unmatched}, Unmatched jumpends = {num_reads_jumpend_unmatched}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f948d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('read_jump_array.npy', read_jump_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0bde74",
   "metadata": {},
   "source": [
    "# Fig 6C\n",
    "# The big jumpmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3281cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_jump_array = np.load('read_jump_array.npy', allow_pickle=True)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=3, figsize=(10,15), layout='constrained')\n",
    "\n",
    "circles_plustoplus = []\n",
    "circles_plustominus = []\n",
    "circles_minustoplus = []\n",
    "circles_minustominus = []\n",
    "\n",
    "jumps_plustoplus = []\n",
    "jumps_plustominus = []\n",
    "jumps_minustoplus = []\n",
    "jumps_minustominus = []\n",
    "\n",
    "off_diagonals = np.zeros(4)\n",
    "on_diagonals = np.zeros(4)\n",
    "mostjumps = read_jump_array.max()\n",
    "\n",
    "radius_scalefactor = 12\n",
    "radii = np.sqrt(read_jump_array)/np.sqrt(mostjumps) * radius_scalefactor\n",
    "\n",
    "legend_jumps = np.array([50000,100000,150000])\n",
    "legend_radii = np.sqrt(legend_jumps)/np.sqrt(mostjumps) * radius_scalefactor\n",
    "legend_circles = []\n",
    "\n",
    "for fromread in range(0,533):\n",
    "    for toread in range(11,544):\n",
    "        jumps = read_jump_array[fromread,toread]\n",
    "        radius = radii[fromread,toread]\n",
    "\n",
    "        if jumps < 2:\n",
    "            continue\n",
    "\n",
    "        if fromread < 272:\n",
    "            # it is from positive strand\n",
    "            if toread < 272:\n",
    "                jumps_plustoplus.append(jumps)\n",
    "                circles_plustoplus.append(plt.Circle((toread+1, fromread+11), radius=radius))\n",
    "                if toread-fromread-10 == 1:\n",
    "                    on_diagonals[0]+=jumps\n",
    "                else:\n",
    "                    off_diagonals[0]+=jumps\n",
    "            else:\n",
    "                jumps_plustominus.append(jumps)\n",
    "                circles_plustominus.append(plt.Circle((554-toread, fromread+11), radius=radius))\n",
    "                off_diagonals[1]+=jumps\n",
    "        else:\n",
    "            if toread < 272:\n",
    "                jumps_minustoplus.append(jumps)\n",
    "                circles_minustoplus.append(plt.Circle((toread+1, 544-fromread), radius=radius))\n",
    "                off_diagonals[2]+=jumps\n",
    "            else:\n",
    "                jumps_minustominus.append(jumps)\n",
    "                circles_minustominus.append(plt.Circle((554-toread, 544-fromread), radius=radius))\n",
    "                if 10-toread+fromread-10 == -11:\n",
    "                    on_diagonals[3]+=jumps\n",
    "                else:\n",
    "                    off_diagonals[3]+=jumps\n",
    "\n",
    "\n",
    "for n, radius in enumerate(legend_radii):\n",
    "    legend_circles.append(plt.Circle((150, 150 + 20 * n), radius = radius))\n",
    "\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n",
    "def set_axes(axis=ax):\n",
    "    ax.set_xlim((0,300))\n",
    "    ax.set_ylim((0,300))\n",
    "\n",
    "cmap = plt.get_cmap('RdPu')\n",
    "new_cmap = truncate_colormap(cmap, 0.3, 1)\n",
    "alpha =0.5\n",
    "\n",
    "for ax in axes.ravel()[0:4]:\n",
    "    template_background = Rectangle((29,29),120,120, facecolor=drtpalette[3], alpha=0.1, ec='k')\n",
    "    ax.add_patch(template_background)\n",
    "\n",
    "cmin = 0\n",
    "cmax = 150000\n",
    "\n",
    "ax = axes.ravel()[3]\n",
    "col = PatchCollection(circles_plustoplus, array = jumps_plustoplus, cmap=new_cmap, alpha=alpha)\n",
    "col.set_clim([cmin,cmax])\n",
    "ax.add_collection(col)\n",
    "ax.set_ylabel(\"from (+ strand)\")\n",
    "ax.set_xlabel(\"to (+ strand)\")\n",
    "set_axes(axis=ax)\n",
    "\n",
    "ax = axes.ravel()[2]\n",
    "col = PatchCollection(circles_plustominus, array = jumps_plustominus, cmap=new_cmap, alpha=alpha)\n",
    "col.set_clim([cmin,cmax])\n",
    "ax.add_collection(col)\n",
    "ax.set_ylabel(\"from (+ strand)\")\n",
    "ax.set_xlabel(\"to (- strand)\")\n",
    "set_axes(axis=ax)\n",
    "\n",
    "\n",
    "ax = axes.ravel()[1]\n",
    "col = PatchCollection(circles_minustoplus, array = jumps_minustoplus, cmap=new_cmap, alpha=alpha)\n",
    "col.set_clim([cmin,cmax])\n",
    "ax.add_collection(col)\n",
    "ax.set_ylabel(\"from (- strand)\")\n",
    "ax.set_xlabel(\"to (+ strand)\")\n",
    "set_axes(axis=ax)\n",
    "\n",
    "ax = axes.ravel()[0]\n",
    "col = PatchCollection(circles_minustominus, array = jumps_minustominus, cmap=new_cmap, alpha=alpha)\n",
    "col.set_clim([cmin,cmax])\n",
    "ax.add_collection(col)\n",
    "ax.set_ylabel(\"from (- strand)\")\n",
    "ax.set_xlabel(\"to (- strand)\")\n",
    "set_axes(axis=ax)\n",
    "\n",
    "\n",
    "\n",
    "# for the legend\n",
    "ax = axes.ravel()[4]\n",
    "col = PatchCollection(legend_circles, array = legend_jumps, cmap=new_cmap, alpha=1)\n",
    "col.set_clim([cmin,cmax])\n",
    "ax.add_collection(col)\n",
    "set_axes(axis=ax)\n",
    "    \n",
    "    \n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.savefig(\"Fig6C.pdf\", transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3db1cf",
   "metadata": {},
   "source": [
    "# Analyse features annotated with RepeatMasker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc86ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "! repeatmasker -e ncbi -pa 36 -q -no_is -nolow -norna -div 40 -lib repeat_masker_features.fasta Group1TrimmedReads.fasta -xm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e17a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_dict={}\n",
    "for seq_record in SeqIO.parse(\"Group1TrimmedReads.fastq\", \"fastq\"):\n",
    "    if seq_record.id not in read_dict:\n",
    "        seq_record.annotations={\"molecule_type\": \"DNA\"}\n",
    "        read_dict[seq_record.id]=seq_record\n",
    "\n",
    "for line in open(\"Group1TrimmedReads.fasta.out.xm\"):\n",
    "    line=line.strip()\n",
    "    line=line.split()\n",
    "    seqid = line[4]\n",
    "    try:\n",
    "        seqr=read_dict[seqid]\n",
    "    except:\n",
    "        continue\n",
    "    readlength=len(seqr)\n",
    "    strand=line[8]\n",
    "    start=int(line[5])\n",
    "    end=int(line[6])\n",
    "    if strand == '+':\n",
    "        feature = SeqFeature(FeatureLocation(start-1, end, +1))\n",
    "    else:\n",
    "        feature = SeqFeature(FeatureLocation(start-1, end, -1))\n",
    "\n",
    "    feature.qualifiers['class']=line[9].split(\"#\")[0]\n",
    "    feature.id=line[9].split(\"#\")[0]\n",
    "    feature.type=line[9].split(\"#\")[0]\n",
    "    seqr.features.append(feature)\n",
    "\n",
    "SeqIO.write(list(read_dict.values()), \"Group1TrimmedReads_annotated.gb\", \"genbank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19691bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse features\n",
    "\n",
    "readiter_f = SeqIO.parse(\"Group1TrimmedReads_annotated.gb\", \"genbank\")\n",
    "num_reads = 0\n",
    "possible_features=[]\n",
    "read_descriptors=[]\n",
    "vector_template={'NanoporeAdapter':0, 'UG2_5prime':1, 'UG2template':2, 'UG2_3prime':3, 'RE1021':4, 'NanoporeAdapter_RC':5, 'UG2_5prime_RC':6, 'UG2template_RC':7, 'UG2_3prime_RC':8, 'RE1021_RC':9, 'SimpleRepeat':10}\n",
    "\n",
    "for record_f in readiter_f:\n",
    "    num_reads += 1\n",
    "    read_descriptor=[]\n",
    "    features = record_f.features\n",
    "    strands = [x.strand for x in features]\n",
    "    types = [x.type for x in features]\n",
    "    for x in zip(types,strands):\n",
    "        if x[1] == -1:\n",
    "            feature_key = x[0]+'_RC'\n",
    "        else:\n",
    "            feature_key = x[0]\n",
    "        if feature_key in vector_template:\n",
    "            feature_index = vector_template[feature_key]\n",
    "        else:\n",
    "            feature_index = vector_template['SimpleRepeat']\n",
    "        if read_descriptor and read_descriptor[-1][feature_index]>0:\n",
    "            read_descriptor[-1][feature_index]+=1\n",
    "        else:\n",
    "            read_descriptor.append(np.zeros(len(vector_template.keys())))\n",
    "            read_descriptor[-1][feature_index]+=1\n",
    "    read_descriptor=np.array(read_descriptor)\n",
    "    read_descriptors.append(read_descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4c9912",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig ,axes = plt.subplots(figsize=(5,6), nrows=2,ncols=2, sharex=True, height_ratios = [1,1], width_ratios = [95,5])\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "ax = axes[0,0]\n",
    "bins=np.arange(0,15,1)\n",
    "ax.hist(length_longest_run,bins=bins,color=hanpink,width=0.9,density=True, align='left',edgecolor='k')\n",
    "ax.set_xlabel(\"number of consecutive antisense repeats\")\n",
    "ax.set_ylabel(\"frequency\")\n",
    "\n",
    "ax = axes[1,0]\n",
    "H, xedge, yedge = np.histogram2d(thresholded_pairs[:,0].astype(int), thresholded_pairs[:,1].astype(int), bins = np.arange(1,15))\n",
    "y,x = np.meshgrid(xedge[:-1], yedge[:-1])\n",
    "mask = H.ravel() > 1\n",
    "threshold = 500\n",
    "color_values = np.minimum(H.ravel()[mask], threshold)\n",
    "sc = ax.scatter(x.ravel()[mask], y.ravel()[mask], c=color_values, cmap='RdPu')\n",
    "ax.set_xlabel(\"number of consecutive antisense repeats\")\n",
    "ax.set_ylabel(\"number of consecutive sense repeats\")\n",
    "ax.plot(np.arange(2,20),np.arange(2,20), c='k')\n",
    "ax.set_xlim((0,15))\n",
    "ax.set_ylim((0,15))\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax = axes[1,1]\n",
    "fig.colorbar(sc, ax = ax, fraction=1, label='number of reads')\n",
    "ax.axis(\"off\")\n",
    "axes[0,1].axis(\"off\")\n",
    "\n",
    "plt.savefig(\"FigS8.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d173d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some example reads with multiple antisense repeats and with 3prime RC region and >500bp in length\n",
    "\n",
    "def draw_arrow(start, length, width, y, pointiness, axis, direction='r', edgecolor='k', fillcolor=hanpink):\n",
    "    if direction == 'r':\n",
    "        axis.fill([start, start+length-pointiness, start+length, start+length-pointiness, start],[y-width/2, y-width/2, y, y+width/2, y+width/2], edgecolor=edgecolor, fc=fillcolor, zorder=100)\n",
    "    else:\n",
    "        axis.fill([start, start+pointiness, start+length, start+length, start+pointiness],[y, y-width/2, y-width/2, y+width/2, y+width/2], edgecolor=edgecolor, fc=fillcolor, zorder=100)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "readiter = SeqIO.parse(\"Group1TrimmedReads_annotated.gb\", \"genbank\")\n",
    "y = 0\n",
    "max_x = 0\n",
    "n=0\n",
    "\n",
    "max_examples = 40\n",
    "example_reads = np.arange(8,20000,100)\n",
    "\n",
    "feature_colors = {\n",
    "    \"UG2_3prime\" : (drtpalette[3],drtpalette[0]),\n",
    "    \"UG2template\" : (hanpink_lightest,hanpink),\n",
    "    \"UG2_5prime\" : (lightestgrey,darkgrey),\n",
    "    \"RE1021\" : ('g','k')\n",
    "}\n",
    "\n",
    "for record in readiter:\n",
    "    n+=1\n",
    "    if len(record) < 500:\n",
    "        continue\n",
    "    if y > max_examples:\n",
    "        break\n",
    "    \n",
    "    read_descriptor = read_descriptors[n-1]   \n",
    "    sense_repeats = read_descriptor[:,vector_template['UG2template']].max()\n",
    "    antisense_repeats = read_descriptor[:,vector_template['UG2template_RC']].max()\n",
    "    if antisense_repeats < 2 :\n",
    "        continue\n",
    "    if read_descriptor[:,vector_template['UG2_3prime_RC']].max() == 0:\n",
    "        continue\n",
    "    \n",
    "    y+=1\n",
    "\n",
    "    #draw whole read\n",
    "    ax.hlines(y, 0, len(record), color='k')\n",
    "\n",
    "    for feature in record.features:\n",
    "        start = int(feature.location.start)\n",
    "        end = int(feature.location.end)\n",
    "        region = feature.type\n",
    "        if end > max_x:\n",
    "            max_x = end\n",
    "        strand = int(feature.location.strand)\n",
    "\n",
    "        if strand == -1:\n",
    "            direction = 'l'\n",
    "            color = feature_colors[region][0]\n",
    "        else:\n",
    "            direction = 'r'\n",
    "            color = feature_colors[region][1]\n",
    "        draw_arrow(start, end-start, 0.5, y, 10, axis = ax, direction = direction, fillcolor=color)\n",
    "    \n",
    "\n",
    "ax.set_xlim((-100,max_x+100))\n",
    "ax.set_ylim((0, y+1))\n",
    "\n",
    "ax.set_xlabel('bp')\n",
    "ax.set_ylabel('read #')\n",
    "plt.savefig(\"FigS8B.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
